{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "# make the module available from the src directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': '../datasets/artificial_data/3d_shapes/volume_40_label_15.pt', 'label': {'size': 15}}, {'image': '../datasets/artificial_data/3d_shapes/volume_0_label_29.pt', 'label': {'size': 29}}, {'image': '../datasets/artificial_data/3d_shapes/volume_10_label_26.pt', 'label': {'size': 26}}, {'image': '../datasets/artificial_data/3d_shapes/volume_15_label_13.pt', 'label': {'size': 13}}, {'image': '../datasets/artificial_data/3d_shapes/volume_39_label_15.pt', 'label': {'size': 15}}, {'image': '../datasets/artificial_data/3d_shapes/volume_37_label_16.pt', 'label': {'size': 16}}, {'image': '../datasets/artificial_data/3d_shapes/volume_38_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_6_label_17.pt', 'label': {'size': 17}}, {'image': '../datasets/artificial_data/3d_shapes/volume_9_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_32_label_22.pt', 'label': {'size': 22}}, {'image': '../datasets/artificial_data/3d_shapes/volume_29_label_11.pt', 'label': {'size': 11}}, {'image': '../datasets/artificial_data/3d_shapes/volume_20_label_21.pt', 'label': {'size': 21}}, {'image': '../datasets/artificial_data/3d_shapes/volume_42_label_26.pt', 'label': {'size': 26}}, {'image': '../datasets/artificial_data/3d_shapes/volume_1_label_21.pt', 'label': {'size': 21}}, {'image': '../datasets/artificial_data/3d_shapes/volume_21_label_17.pt', 'label': {'size': 17}}, {'image': '../datasets/artificial_data/3d_shapes/volume_34_label_27.pt', 'label': {'size': 27}}, {'image': '../datasets/artificial_data/3d_shapes/volume_3_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_48_label_16.pt', 'label': {'size': 16}}, {'image': '../datasets/artificial_data/3d_shapes/volume_28_label_17.pt', 'label': {'size': 17}}, {'image': '../datasets/artificial_data/3d_shapes/volume_18_label_11.pt', 'label': {'size': 11}}, {'image': '../datasets/artificial_data/3d_shapes/volume_27_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_14_label_21.pt', 'label': {'size': 21}}, {'image': '../datasets/artificial_data/3d_shapes/volume_44_label_26.pt', 'label': {'size': 26}}, {'image': '../datasets/artificial_data/3d_shapes/volume_31_label_27.pt', 'label': {'size': 27}}, {'image': '../datasets/artificial_data/3d_shapes/volume_24_label_24.pt', 'label': {'size': 24}}, {'image': '../datasets/artificial_data/3d_shapes/volume_5_label_14.pt', 'label': {'size': 14}}, {'image': '../datasets/artificial_data/3d_shapes/volume_8_label_28.pt', 'label': {'size': 28}}, {'image': '../datasets/artificial_data/3d_shapes/volume_13_label_25.pt', 'label': {'size': 25}}, {'image': '../datasets/artificial_data/3d_shapes/volume_12_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_41_label_24.pt', 'label': {'size': 24}}, {'image': '../datasets/artificial_data/3d_shapes/volume_49_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_7_label_17.pt', 'label': {'size': 17}}, {'image': '../datasets/artificial_data/3d_shapes/volume_33_label_23.pt', 'label': {'size': 23}}, {'image': '../datasets/artificial_data/3d_shapes/volume_16_label_11.pt', 'label': {'size': 11}}, {'image': '../datasets/artificial_data/3d_shapes/volume_26_label_28.pt', 'label': {'size': 28}}, {'image': '../datasets/artificial_data/3d_shapes/volume_19_label_20.pt', 'label': {'size': 20}}, {'image': '../datasets/artificial_data/3d_shapes/volume_45_label_12.pt', 'label': {'size': 12}}, {'image': '../datasets/artificial_data/3d_shapes/volume_4_label_13.pt', 'label': {'size': 13}}, {'image': '../datasets/artificial_data/3d_shapes/volume_2_label_29.pt', 'label': {'size': 29}}, {'image': '../datasets/artificial_data/3d_shapes/volume_46_label_29.pt', 'label': {'size': 29}}, {'image': '../datasets/artificial_data/3d_shapes/volume_43_label_28.pt', 'label': {'size': 28}}, {'image': '../datasets/artificial_data/3d_shapes/volume_17_label_26.pt', 'label': {'size': 26}}, {'image': '../datasets/artificial_data/3d_shapes/volume_35_label_23.pt', 'label': {'size': 23}}, {'image': '../datasets/artificial_data/3d_shapes/volume_22_label_15.pt', 'label': {'size': 15}}, {'image': '../datasets/artificial_data/3d_shapes/volume_25_label_26.pt', 'label': {'size': 26}}, {'image': '../datasets/artificial_data/3d_shapes/volume_11_label_18.pt', 'label': {'size': 18}}, {'image': '../datasets/artificial_data/3d_shapes/volume_30_label_26.pt', 'label': {'size': 26}}, {'image': '../datasets/artificial_data/3d_shapes/volume_47_label_21.pt', 'label': {'size': 21}}, {'image': '../datasets/artificial_data/3d_shapes/volume_23_label_28.pt', 'label': {'size': 28}}, {'image': '../datasets/artificial_data/3d_shapes/volume_36_label_18.pt', 'label': {'size': 18}}]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../datasets/artificial_data/3d_shapes\"\n",
    "\n",
    "def create_list():\n",
    "    pairs = []\n",
    "    all_files = os.listdir(data_dir)\n",
    "    for filename in all_files:\n",
    "        label = int(filename.split(\"_\").pop().replace(\".pt\", \"\"))\n",
    "        label_dict = { \"size\": label }\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        pairs.append({\"image\": file_path, \"label\": label_dict})\n",
    "    return pairs\n",
    "\n",
    "pairs = create_list()\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/askelundsgaard/opt/anaconda3/envs/MLA/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/askelundsgaard/opt/anaconda3/envs/MLA/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/askelundsgaard/opt/anaconda3/envs/MLA/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <D2077E4D-18BC-34B9-8A9B-1EF634A0F416> /Users/askelundsgaard/opt/anaconda3/envs/MLA/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from src.transformers.TensorLoaderTransfomer import TensorLoader\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstD, ScaleIntensityd, ToTensord, ResizeD, Lambdad, NormalizeIntensityD\n",
    "\n",
    "from src.transformers.SliceTransformer import SliceAggregateTransform\n",
    "importlib.reload(sys.modules['src.transformers.SliceTransformer'])\n",
    "\n",
    "importlib.reload(sys.modules['src.transformers.TensorLoaderTransfomer'])\n",
    "transforms = [\n",
    "    TensorLoader(keys=[\"image\"]),\n",
    "    ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, factor=1.0),\n",
    "    NormalizeIntensityD(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataLoaders.NiftiDataLoader2' from '/Users/askelundsgaard/Documents/datalogi/6-semester/Bachelor/XAI-in-Medical-Image-Analysis/src/dataLoaders/NiftiDataLoader2.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataLoaders.NiftiDataLoader2 import NiftiDataLoader\n",
    "importlib.reload(sys.modules['src.dataLoaders.NiftiDataLoader2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/askelundsgaard/Documents/datalogi/6-semester/Bachelor/XAI-in-Medical-Image-Analysis/src/dataLoaders/saved_data_lists/data_list.pkl does not exist.\n",
      "Data list loaded: False\n",
      "Using custom sampler: False\n",
      "Subset size: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 40/40 [00:10<00:00,  3.88it/s]\n",
      "Loading dataset: 100%|██████████| 5/5 [00:01<00:00,  3.04it/s]\n",
      "Loading dataset: 100%|██████████| 5/5 [00:01<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'niftiShort'\n",
    "data_path = '../datasets/nifti/'\n",
    "data_dir = f'{data_path}{dataset}'\n",
    "\n",
    "# data_dir = 'C:/Users/askel/Downloads/NIFTY/NIFTY/'\n",
    "# max = 8876\n",
    "dim = 384\n",
    "data_loader = NiftiDataLoader(data_dir=data_dir, \n",
    "                              batch_size=32,\n",
    "                              spatial_resize=(dim, dim, dim),\n",
    "                              cache_rate=0.5, \n",
    "                              replace_rate=1,\n",
    "                              transforms=transforms,\n",
    "                              data_list=pairs,\n",
    "                              )\n",
    "# data_loader.load_data(visit_no=visit, subset_size=2058, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=84, cache=\"standard\")\n",
    "#data_loader.load_data(subset_size=4400, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=8875, cache=\"standard\")\n",
    "\n",
    "data_loader.load_data(cache=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models.medical_models.base_medical' from '/Users/askelundsgaard/Documents/datalogi/6-semester/Bachelor/XAI-in-Medical-Image-Analysis/src/models/medical_models/base_medical.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.medical_models.monai_resnet import MonaiMedicalResNet\n",
    "importlib.reload(sys.modules['src.models.medical_models.monai_resnet'])\n",
    "importlib.reload(sys.modules['src.models.medical_models.base_medical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader train loader:  2 40\n",
      "Image spatial dimensions:  torch.Size([32, 256, 256, 256])\n",
      "Number of input channels:  256\n",
      "Spatial dims:  2\n",
      "gpu:  cpu\n",
      "Is cuda available:  False cpu\n",
      "Number of training images: 40\n"
     ]
    }
   ],
   "source": [
    "fusion_model = MonaiMedicalResNet(\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    data_loader=data_loader,\n",
    "    dropout_rate=0.1,\n",
    "    depth=18,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "fusion_model.train()\n",
    "fusion_model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
