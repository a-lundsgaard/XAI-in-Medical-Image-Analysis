{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "# make the module available from the src directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataLoaders.PatientDataLoader' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\dataLoaders\\\\PatientDataLoader.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataLoaders.PatientDataLoader import PatientDataProcessor\n",
    "importlib.reload(sys.modules['src.dataLoaders.PatientDataLoader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_folder = 'OAIData21/'\n",
    "data_path = '../datasets/meta_data/' + meta_folder\n",
    "\n",
    "processor = PatientDataProcessor(base_path=data_path)\n",
    "meta_data = processor.load_all_clinical_data(labels=[\"WOMKP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V00AGE</th>\n",
       "      <th>V00WOMKPL</th>\n",
       "      <th>V00WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V01AGE</th>\n",
       "      <th>V01WOMKPL</th>\n",
       "      <th>V01WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V02AGE</th>\n",
       "      <th>V02WOMKPL</th>\n",
       "      <th>...</th>\n",
       "      <th>V09WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V10AGE</th>\n",
       "      <th>V10WOMKPL</th>\n",
       "      <th>V10WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V11AGE</th>\n",
       "      <th>V11WOMKPL</th>\n",
       "      <th>V11WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9000099</th>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000296</th>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000622</th>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000798</th>\n",
       "      <td>56</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9001104</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999365</th>\n",
       "      <td>56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999510</th>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999862</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999865</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999878</th>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4796 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V00AGE  V00WOMKPL  V00WOMKPR  Sex  V01AGE  V01WOMKPL  V01WOMKPR  Sex  \\\n",
       "ID                                                                              \n",
       "9000099      59        0.0        1.0    0    60.0        0.0        0.0    0   \n",
       "9000296      69        0.0        0.0    0    70.0        0.0        0.0    0   \n",
       "9000622      71        0.0        3.0    1    72.0        0.0        2.0    1   \n",
       "9000798      56        8.0        0.0    0    58.0        8.0        0.0    0   \n",
       "9001104      72        0.0        4.0    1    73.0        0.0        1.0    1   \n",
       "...         ...        ...        ...  ...     ...        ...        ...  ...   \n",
       "9999365      56        4.0        5.0    0    57.0        3.0        5.0    0   \n",
       "9999510      50        3.0        0.0    0    51.0        1.0        0.0    0   \n",
       "9999862      61        0.0        0.0    1    62.0        0.0        0.0    1   \n",
       "9999865      61        0.0        0.0    1    62.0        0.0        0.0    1   \n",
       "9999878      72        1.0        1.0    1    73.0        1.0        0.0    1   \n",
       "\n",
       "         V02AGE  V02WOMKPL  ...  V09WOMKPR  Sex  V10AGE  V10WOMKPL  V10WOMKPR  \\\n",
       "ID                          ...                                                 \n",
       "9000099     NaN        NaN  ...        0.0    0    66.0        4.0        3.0   \n",
       "9000296     NaN        NaN  ...        0.0    0    77.0        0.0        0.0   \n",
       "9000622     NaN        NaN  ...               1     NaN        NaN        NaN   \n",
       "9000798    58.0        7.0  ...        0.0    0    64.0        5.0        0.0   \n",
       "9001104     NaN        NaN  ...               1    80.0        0.0        1.0   \n",
       "...         ...        ...  ...        ...  ...     ...        ...        ...   \n",
       "9999365     NaN        NaN  ...        1.0    0    64.0        4.0        2.0   \n",
       "9999510     NaN        NaN  ...        1.0    0    58.0        3.0        0.0   \n",
       "9999862     NaN        NaN  ...        0.0    1    69.0        0.0        0.0   \n",
       "9999865     NaN        NaN  ...        0.0    1    69.0        3.0        1.0   \n",
       "9999878     NaN        NaN  ...        0.0    1    79.0        1.0        1.0   \n",
       "\n",
       "         Sex  V11AGE  V11WOMKPL  V11WOMKPR  Sex  \n",
       "ID                                               \n",
       "9000099    0    67.0        4.0        2.0    0  \n",
       "9000296    0    78.0        0.0        0.0    0  \n",
       "9000622    1     NaN        NaN        NaN    1  \n",
       "9000798    0    65.0        3.0        0.0    0  \n",
       "9001104    1     NaN        NaN        NaN    1  \n",
       "...      ...     ...        ...        ...  ...  \n",
       "9999365    0    65.0        5.0        6.0    0  \n",
       "9999510    0    59.0        4.0        0.0    0  \n",
       "9999862    1    70.0        0.0        0.0    1  \n",
       "9999865    1    70.0        0.0        0.0    1  \n",
       "9999878    1    80.0        2.0        1.0    1  \n",
       "\n",
       "[4796 rows x 48 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.SliceTransformer import SliceAggregateTransform\n",
    "importlib.reload(sys.modules['src.transformers.SliceTransformer'])\n",
    "custom_transforms = [SliceAggregateTransform(keys=[\"image\"], slices=9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataLoaders.NiftiDataLoader2' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\dataLoaders\\\\NiftiDataLoader2.py'>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataLoaders.NiftiDataLoader2 import NiftiDataLoader\n",
    "importlib.reload(sys.modules['src.dataLoaders.NiftiDataLoader2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\saved_data_lists\\data_list.pkl does not exist.\n",
      "Data list loaded: False\n",
      "File c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\saved_data_lists\\data_list.pkl does not exist.\n",
      "Visits: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
      "Total images detected: 8871\n",
      "Subset size: 8871\n",
      "Train indices: [3206  163 2631 ... 6503 1838 3420]\n",
      "Val indices: [ 22 126 823 687 163 119 869 861 655  63 705 272 391 757 636  50  26 520\n",
      " 561 793 242 269 449 797   2 225 696 313 684 843 577 881 611 291 208 412\n",
      " 480 357 220 227 114 116  12 477 135 205 763 252 723 792 697 526  35 307\n",
      " 197 342 210 341 567 563 571 737 463 816 276 437 672 117 173 791 403 199\n",
      " 476 863 304 246 506 444 130 164 439 704 318 105  77 562 588 374 629  82\n",
      " 445 169 207 306 754  80 544 420 360 435 750 538 740  18 333 514  42 848\n",
      " 782 730 429  37 284 535 438 472 261 409 487 158 618 780 256 775 758 443\n",
      " 624 560  93 701 159 128  88 298 761 326 689 620 405 803 882 847 665 626\n",
      " 484 294 408 795  74 349 870 426 247 251 733 422 448  13 604 819 430  59\n",
      " 719 831 685 319 248 221 707 499 167 515 866 576 593 720 305  16 747 417\n",
      " 854 625 259 527 867 681  28 732   8 799 393 746 543 692 303 879 548 632\n",
      " 691 249 352 614 278 501 682 853 254 350 644 370 855 575 671 518  95 348\n",
      " 690 258 211 102 353 712 388   4 637 783 532 455 182 736 615 407 165 635\n",
      " 837 133 121  86   7 840 239 781 776 699 764 217 277 282 752 541 592 703\n",
      "  96 530 458 236 885 314 500 827 817 204 174 375 216 857 162 659 440 640\n",
      " 610 320 273 386 390 110 457 607 281 270 552  61 489 466 849 579 371 325\n",
      "  45 263 397 345 108 833 381 336 200 762 488 315 753 748 260 275 441 404\n",
      " 411 340 361 675 582 363 118 794 140 431 109 807 493 643 739 829 106 805\n",
      " 131 389 566 702 574 418 219 547 826 235 415 550 268  71 887 470 809 513\n",
      " 824 280 450 421 301 710 727  38 528 570 666 202 534 872  60 491 531 212\n",
      " 812  23 471 613 191 798 641 482 769 790 765   3 138  65 505 419 851 127\n",
      " 464 257 871 379  24  32 406 554 668 621 399  55  20 481 589  72 553 425\n",
      " 478  33 153 617  19 344 245  57 364  73 785 461 495 267 322 442 815 802\n",
      " 771 168 355 293 631 433 508  84  34 578  85 864 839 770  10  79 873 392\n",
      " 321 510 715  36 100 678 537 718 423 601 676  21 728 713 183 185 396 317\n",
      " 841 741 716  17 486 229 842 215 580 880 801 597 767 331 814 664 786 698\n",
      " 180 779  90 735 378 401 120 669 742 667 693 460 465 299 777  81  30 605\n",
      " 356 646 112 143 237 295 485 104 255 503 347 497 115 836 262 175 496 602\n",
      " 584 868 103 160 654 533 700 233 768 145 661 387 673 188 594 324 494 223\n",
      " 670 858 385 711 296 549 178 821 663 832 731 788 469 622 504 642 492  41\n",
      " 634 330 883 244 187 311 876 382 756 250  14 156 649 193 822 308 151 209\n",
      " 586 176  98 555 206 572 137 309 222 192 875 850 818 724 521 773 300 609\n",
      "  39 231 557 475 558 859 498 124 565 743 796 808 706 213  31 573 243 283\n",
      " 714 400 877 722 410 686 507 177 709 856 377  66 446 717 519 619  56 144\n",
      " 424 474 657 623 287 865 454 766  54  47 725 744 230 372  89 228 568 511\n",
      " 627  53  94 198 376  67 195 338  68 600 603 335 679 695 365 662 490 327\n",
      " 810 688 214 452  92 599  69  78 186 862 398 784 628 265 633  52 542 329\n",
      " 608 286 323  64 150 645  58 155 483  43 656 751 749 585 290 232 708  76\n",
      " 653 616 111 413 434 734 502 316 337 328 234  70 190 134 451 835 148  97\n",
      " 590   9 416 536 125  40 509 517 694 113 524 264 612 359 884 218 203 170\n",
      " 759 462 804 658 166 551 107 354 181 414 774 184 141  25 241 591 288 312\n",
      " 559 545 846 587 830 595 738  46 755 343 179 745 523  99 581 825  48 310\n",
      " 467 569 651 800   5  75 302 886 648  91 226 129 683 760 152 384 820 844\n",
      " 297 266 146 787 479 402   0 122 289  49  62 834 453 154 139 726 149 596\n",
      " 878 583  29 380 147 540 142 351 346 811  83 161 196 123 279 285 459 383\n",
      " 539 334 172 292 845 546 339 556 101 367 512 194 721 136  44 778 132 456\n",
      " 525 652   6 366 606  15 368 772 630  11 358 729 806 436 789 395 874 680\n",
      " 647 516 171 813 639 522 638 529 201 238 660 828 852   1 427 271 253 428\n",
      " 860 468 677 564 373 650  27 332 274 598 838 189  51 369 473 157 432 394\n",
      " 240 224 362  87 447]\n",
      "Test indices: [ 14 687 767 154 384 772   2 599 353 488 346 236 441 165 469 855 511 679\n",
      "  83 788 713 390 397 761 864 321 689 404 541 149 507 674 269 629 318 715\n",
      " 578 468 837  33 234 370 330 627 619 309 237  25 325 282 166 442 244 205\n",
      " 763 143 640 684  29 652 434 433 673 424 380 749 545 105 853 420 170 814\n",
      " 287 584 838 421 286 872 881 292 379 296  82 191 827 338 340  84 280 558\n",
      " 786 747 299 571 323 682 589 595 613 110 731 859 261 765 182 230 474 538\n",
      " 631 598 366 494  71 132 817 551 707 559 656  18  20 400 210 138 377  64\n",
      " 882 582  68 675 692 504  67 359 651  58 638  91 816 730 701 336 151 490\n",
      " 732 399 257  97 792 454 215 381 117 569 567 509 601 768  57 867 741 238\n",
      " 231 840 861 427 485 739 415 209 229 432 216 137 395 127 482 288 690 113\n",
      " 298 776 341 360 304 800 616 843 774  15 319 402 188 372 478  93 268 148\n",
      " 124 147 593 829 307 845 773 260 409 738 791 452 310 733 550 272 850 365\n",
      "  95 563 383  41 426 126 828 355 528 770 561 591 453 623 745 841 500 801\n",
      " 556 795 678 264 175 794 759 245 650 758 160  42 615 114 437  48  16 519\n",
      " 573 565 196 130 821 354  80 576 204 570 475 636 662 180 112 259 281 596\n",
      " 246 721 653 535 537 825  61  63 422 695 512 481  39 146 248 854   9 572\n",
      " 592 637 514 734 329  23 440 611 527  30 408 349 548 100 295 219 523 885\n",
      " 279 293 308 466   7 521 493  13 479 300 414 472 429 163 241 659 423  34\n",
      " 660  76 265 242 883  59 753 604 134 628  28 285  73 484 502 781 712 807\n",
      " 698 382 834 302 644 831 866 766 622 430  62 184 727 223 335 374 373  47\n",
      " 750 203  27 819 847 391 540 283 328 498 467 683  46 378  78 436 256 156\n",
      " 667 294 714 411 868 459 228 102 704 211 174 600 120 723 666 343 439 581\n",
      " 334 587 407 217 858 125 115 387 811 243 823 448 784 607  11 194 645 275\n",
      " 737  36 790 200 832 708  53 709 746 777 805 848 620 649 547 797 121 362\n",
      " 393  89 756 752  26 751 106 416 771 532 172 385 486 614 317 575 233 496\n",
      " 544 291 419 206 144 456 142 262 862 878 347 664 562 803 111  49 412 665\n",
      " 697 103  75 602 655 464 450 396 118 871 107 492 647 706 699 221 530 131\n",
      " 109 688  38 806 352  51 796 725 284  45 339 879  96 641 669 254  69 608\n",
      "  37 718 625 369 290 748  92 505 443 193  52 119 663 787 497 278 516  94\n",
      " 173 728  44 247 836 438 201 225 724 884 164 326 588 617 226 646 108 358\n",
      " 632 458 455  24 190 780 583 446 557 140 703 153 873 691 590 626 705 860\n",
      " 702 624 213 487  19 670 520 403 657 686  31 332 344 495  54 621 176 822\n",
      " 560 435 367 161 141 145 356 313 813 157 711 694 222 386 844 333 159 522\n",
      " 648 445 566 818  74 658 251 483 536  12 553 681 186 542 312   1 271 168\n",
      " 779 471 394 388  60   8 410 128 835 824 361 580 224 263 273 742 740 177\n",
      " 376 253 428 457 633 525 585 685 710 719 406 887 289  70  81 218 413 630\n",
      " 555 849 178 465 826 552 722 549 506 610 305 812 451 798 863 877 635 401\n",
      " 136 449  40 187 634  79 155 116 398 594   0  22 671  43 693 266 461 162\n",
      " 375 460 220 133 192  32 676 276 830 122 782 235 716 668 123 757 250  55\n",
      " 543 331 865 775 661 314  88 717 809 642 654 852 324 743  17 368 179 680\n",
      "  99 518 501 337 198 258 851 554  85  65 597 315 150 875 764 167 605 447\n",
      " 510 311 534   5 677 762 603 389 489 574 736 431 744 101  35 533 833 104\n",
      " 363  77 345 539 202 529  86 470 508 524 612  87 870 729 212 392 876 303\n",
      " 869 322 700 672 183 342 735 473 789 778 405 306 207 783 606 820 350 477\n",
      " 195 301 240 252 274 462 185 886 197 564 880 515 214 857 839  21 135   3\n",
      " 351 754 371 444 696   6 208 579 815 463 181  72 255 760 568 270 417 139\n",
      " 846 491 513 320 785 793  98  66 171 297 425 499 799 480  90 364 643 348\n",
      "   4 856 239 769 526 810 577 357  50 609 546 169 316  10 808 804  56 586\n",
      " 517 227 249 842 199 189 618 726 639 476 755 802 277 129 267 418 152 232\n",
      " 158 503 327 874 531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  33%|███▎      | 2345/7095 [26:42<54:05,  1.46it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\multiprocessing\\pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 21\u001b[0m\n\u001b[0;32m      8\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m NiftiDataLoader(data_dir\u001b[38;5;241m=\u001b[39mdata_dir, \n\u001b[0;32m      9\u001b[0m                               meta_data_loader\u001b[38;5;241m=\u001b[39mprocessor,\n\u001b[0;32m     10\u001b[0m                               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m                               custom_transforms\u001b[38;5;241m=\u001b[39mcustom_transforms,\n\u001b[0;32m     15\u001b[0m                               )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# data_loader.load_data(visit_no=visit, subset_size=2058, cache=\"standard\")\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# data_loader.load_data(subset_size=84, cache=\"standard\")\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#data_loader.load_data(subset_size=4400, cache=\"standard\")\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# data_loader.load_data(subset_size=8875, cache=\"standard\")\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\NiftiDataLoader2.py:104\u001b[0m, in \u001b[0;36mNiftiDataLoader.load_data\u001b[1;34m(self, subset_size, cache)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_persistent_cache_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, test_indices, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cache \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_cache_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_cache_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data, val_indices)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_cache_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, test_indices)\n",
      "File \u001b[1;32mc:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\NiftiDataLoader2.py:125\u001b[0m, in \u001b[0;36mNiftiDataLoader.create_cache_dataset\u001b[1;34m(self, data, indices)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_cache_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, indices):\n\u001b[0;32m    124\u001b[0m     subset_data \u001b[38;5;241m=\u001b[39m [data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCacheDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavailable_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py:823\u001b[0m, in \u001b[0;36mCacheDataset.__init__\u001b[1;34m(self, data, transform, cache_num, cache_rate, num_workers, progress, copy_cache, as_contiguous, hash_as_key, hash_func, runtime_cache)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m ListProxy \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hash_keys: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 823\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py:850\u001b[0m, in \u001b[0;36mCacheDataset.set_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    847\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_num))\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime_cache \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# prepare cache content immediately\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime_cache, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruntime_cache:\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# this must be in the main process, not in dataloader's workers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py:879\u001b[0m, in \u001b[0;36mCacheDataset._fill_cache\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress \u001b[38;5;129;01mand\u001b[39;00m has_tqdm:\n\u001b[1;32m--> 879\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tqdm(p\u001b[38;5;241m.\u001b[39mimap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_cache_item, indices), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(indices), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(p\u001b[38;5;241m.\u001b[39mimap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_cache_item, indices))\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\multiprocessing\\pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = 'niftiShort'\n",
    "data_path = '../datasets/nifti/'\n",
    "data_dir = f'{data_path}{dataset}'\n",
    "\n",
    "data_dir = 'C:/Users/askel/Downloads/NIFTY/NIFTY/'\n",
    "# max = 8876\n",
    "dim = 384\n",
    "data_loader = NiftiDataLoader(data_dir=data_dir, \n",
    "                              meta_data_loader=processor,\n",
    "                              batch_size=32,\n",
    "                              spatial_resize=(dim, dim, dim),\n",
    "                              cache_rate=0.5, \n",
    "                              replace_rate=1, \n",
    "                              custom_transforms=custom_transforms,\n",
    "                              )\n",
    "# data_loader.load_data(visit_no=visit, subset_size=2058, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=84, cache=\"standard\")\n",
    "#data_loader.load_data(subset_size=4400, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=8875, cache=\"standard\")\n",
    "\n",
    "data_loader.load_data(cache=\"standard\", subset_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.custom_transforms = [SliceAggregateTransform(keys=[\"image\"], slices=9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models.medical_models.monai_resnet' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\models\\\\medical_models\\\\monai_resnet.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.models.baseModels.resnet_3D_monai import MedicalResNetModel\n",
    "# importlib.reload(sys.modules['src.models.baseModels.resnet_3D_monai'])\n",
    "\n",
    "from src.models.medical_models.medical_resnet import MedicalResNetModel\n",
    "importlib.reload(sys.modules['src.models.medical_models.base_medical'])\n",
    "importlib.reload(sys.modules['src.models.medical_models.medical_resnet'])\n",
    "\n",
    "\n",
    "from src.models.medical_models.monai_resnet import MonaiMedicalResNet\n",
    "importlib.reload(sys.modules['src.models.medical_models.monai_resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader.train_loader.dataset[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader train loader:  16 487\n",
      "Image spatial dimensions:  torch.Size([32, 6, 384, 384])\n",
      "Number of input channels:  6\n",
      "gpu:  cuda:0\n",
      "Is cuda available:  True cuda\n",
      "Number of training images: 487\n",
      "Epoch 1/200, Train Loss: 3.8130144448950887, Val Loss: 4.520919322967529, R^2 Score: -13.121465682983398\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_1_val_4.52.pth\n",
      "Epoch 2/200, Train Loss: 0.40791387762874365, Val Loss: 1.073105275630951, R^2 Score: -2.315981149673462\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_2_val_1.07.pth\n",
      "Epoch 3/200, Train Loss: 0.4189968705177307, Val Loss: 0.34047622978687286, R^2 Score: -0.053806424140930176\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_3_val_0.34.pth\n",
      "Epoch 4/200, Train Loss: 0.38896629866212606, Val Loss: 0.5494126975536346, R^2 Score: -0.687801718711853\n",
      "Epoch 5/200, Train Loss: 0.39115446899086237, Val Loss: 0.28405003249645233, R^2 Score: 0.12210798263549805\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_5_val_0.28.pth\n",
      "Epoch 6/200, Train Loss: 0.41137690376490355, Val Loss: 0.39972759783267975, R^2 Score: -0.24081337451934814\n",
      "Epoch 7/200, Train Loss: 0.3892871793359518, Val Loss: 0.40188661217689514, R^2 Score: -0.24973571300506592\n",
      "Epoch 8/200, Train Loss: 0.332607907243073, Val Loss: 0.3381401002407074, R^2 Score: -0.04924798011779785\n",
      "Epoch 9/200, Train Loss: 0.32266275864094496, Val Loss: 0.3083302527666092, R^2 Score: 0.03228873014450073\n",
      "Epoch 10/200, Train Loss: 0.3022639360278845, Val Loss: 0.3613816648721695, R^2 Score: -0.13308405876159668\n",
      "Epoch 11/200, Train Loss: 0.290376347489655, Val Loss: 0.3430790454149246, R^2 Score: -0.08031725883483887\n",
      "Epoch 12/200, Train Loss: 0.29758360935375094, Val Loss: 0.3476346582174301, R^2 Score: -0.0825873613357544\n",
      "Epoch 13/200, Train Loss: 0.2769156927242875, Val Loss: 0.39978405833244324, R^2 Score: -0.2449558973312378\n",
      "Epoch 14/200, Train Loss: 0.27614907547831535, Val Loss: 0.2760802134871483, R^2 Score: 0.13331472873687744\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_14_val_0.28.pth\n",
      "Epoch 15/200, Train Loss: 0.23622379824519157, Val Loss: 0.31046225130558014, R^2 Score: 0.03214406967163086\n",
      "Epoch 16/200, Train Loss: 0.22197076445445418, Val Loss: 0.3297514021396637, R^2 Score: -0.03365588188171387\n",
      "Epoch 17/200, Train Loss: 0.18160417210310698, Val Loss: 0.5455898344516754, R^2 Score: -0.6970384120941162\n",
      "Epoch 18/200, Train Loss: 0.24330831225961447, Val Loss: 0.5310076922178268, R^2 Score: -0.6630810499191284\n",
      "Epoch 19/200, Train Loss: 0.21365985414013267, Val Loss: 0.30554142594337463, R^2 Score: 0.03803586959838867\n",
      "Epoch 20/200, Train Loss: 0.1372881019487977, Val Loss: 0.25569333881139755, R^2 Score: 0.1999187469482422\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_20_val_0.26.pth\n",
      "Epoch 21/200, Train Loss: 0.14379970962181687, Val Loss: 0.36797863245010376, R^2 Score: -0.1582646369934082\n",
      "Epoch 22/200, Train Loss: 0.13392071053385735, Val Loss: 0.2958555966615677, R^2 Score: 0.06969344615936279\n",
      "Epoch 23/200, Train Loss: 0.1076849140226841, Val Loss: 0.4190370738506317, R^2 Score: -0.31312620639801025\n",
      "Epoch 24/200, Train Loss: 0.09133685263805091, Val Loss: 0.3776361048221588, R^2 Score: -0.1846473217010498\n",
      "Epoch 25/200, Train Loss: 0.0884653200628236, Val Loss: 0.3399946242570877, R^2 Score: -0.06377625465393066\n",
      "Epoch 26/200, Train Loss: 0.11001428705640137, Val Loss: 0.2815024256706238, R^2 Score: 0.11957883834838867\n",
      "Epoch 27/200, Train Loss: 0.10818444355390966, Val Loss: 0.27556295692920685, R^2 Score: 0.13904285430908203\n",
      "Epoch 28/200, Train Loss: 0.11825909395702183, Val Loss: 0.2721770703792572, R^2 Score: 0.14822465181350708\n",
      "Epoch 29/200, Train Loss: 0.10973683069460094, Val Loss: 0.2947744131088257, R^2 Score: 0.07422453165054321\n",
      "Epoch 30/200, Train Loss: 0.12072847806848586, Val Loss: 0.3678772747516632, R^2 Score: -0.15640497207641602\n",
      "Epoch 31/200, Train Loss: 0.08997706393711269, Val Loss: 0.34928689897060394, R^2 Score: -0.09328341484069824\n",
      "Epoch 32/200, Train Loss: 0.0750654973089695, Val Loss: 0.23197564482688904, R^2 Score: 0.2725674510002136\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_32_val_0.23.pth\n",
      "Epoch 33/200, Train Loss: 0.07425936800427735, Val Loss: 0.35543155670166016, R^2 Score: -0.1196976900100708\n",
      "Epoch 34/200, Train Loss: 0.06543815927579999, Val Loss: 0.2440730556845665, R^2 Score: 0.23629140853881836\n",
      "Epoch 35/200, Train Loss: 0.07263092044740915, Val Loss: 0.36396948993206024, R^2 Score: -0.1338181495666504\n",
      "Epoch 36/200, Train Loss: 0.08130753331352025, Val Loss: 0.25831741094589233, R^2 Score: 0.192127525806427\n",
      "Epoch 37/200, Train Loss: 0.06604833656456321, Val Loss: 0.22183096408843994, R^2 Score: 0.30331045389175415\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_37_val_0.22.pth\n",
      "Epoch 38/200, Train Loss: 0.06104532419703901, Val Loss: 0.22583843767642975, R^2 Score: 0.29083847999572754\n",
      "Epoch 39/200, Train Loss: 0.060661964933387935, Val Loss: 0.20922527462244034, R^2 Score: 0.34083157777786255\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_39_val_0.21.pth\n",
      "Epoch 40/200, Train Loss: 0.06607422709930688, Val Loss: 0.26566188782453537, R^2 Score: 0.16544079780578613\n",
      "Epoch 41/200, Train Loss: 0.05996732646599412, Val Loss: 0.2493109554052353, R^2 Score: 0.21688711643218994\n",
      "Epoch 42/200, Train Loss: 0.0667758887866512, Val Loss: 0.25037291646003723, R^2 Score: 0.21430569887161255\n",
      "Epoch 43/200, Train Loss: 0.05771698197349906, Val Loss: 0.22955073416233063, R^2 Score: 0.2791479229927063\n",
      "Epoch 44/200, Train Loss: 0.05998362286482006, Val Loss: 0.2631736174225807, R^2 Score: 0.16945773363113403\n",
      "Epoch 45/200, Train Loss: 0.054162963293492794, Val Loss: 0.2430681213736534, R^2 Score: 0.2382158637046814\n",
      "Epoch 46/200, Train Loss: 0.050103261950425804, Val Loss: 0.23133444786071777, R^2 Score: 0.27191704511642456\n",
      "Epoch 47/200, Train Loss: 0.05119907797779888, Val Loss: 0.23292485624551773, R^2 Score: 0.2645057439804077\n",
      "Epoch 48/200, Train Loss: 0.07059959613252431, Val Loss: 0.2811194509267807, R^2 Score: 0.11831766366958618\n",
      "Epoch 49/200, Train Loss: 0.055749749997630715, Val Loss: 0.250922828912735, R^2 Score: 0.21307313442230225\n",
      "Epoch 50/200, Train Loss: 0.0525729542132467, Val Loss: 0.23132916539907455, R^2 Score: 0.2754977345466614\n",
      "Epoch 51/200, Train Loss: 0.04250989470165223, Val Loss: 0.25275808572769165, R^2 Score: 0.20467764139175415\n",
      "Epoch 52/200, Train Loss: 0.04932170419488102, Val Loss: 0.3139422833919525, R^2 Score: 0.018560826778411865\n",
      "Epoch 53/200, Train Loss: 0.06886620447039604, Val Loss: 0.23986348509788513, R^2 Score: 0.2446029782295227\n",
      "Epoch 54/200, Train Loss: 0.04839605570305139, Val Loss: 0.23059077560901642, R^2 Score: 0.2766892910003662\n",
      "Epoch 55/200, Train Loss: 0.05214825691655278, Val Loss: 0.25191403180360794, R^2 Score: 0.21339738368988037\n",
      "Epoch 56/200, Train Loss: 0.055200660484842956, Val Loss: 0.2644602358341217, R^2 Score: 0.17236346006393433\n",
      "Epoch 57/200, Train Loss: 0.0734784024534747, Val Loss: 0.2549833431839943, R^2 Score: 0.20066553354263306\n",
      "Epoch 58/200, Train Loss: 0.048427231959067285, Val Loss: 0.26608341932296753, R^2 Score: 0.16437137126922607\n",
      "Epoch 59/200, Train Loss: 0.05146378627978265, Val Loss: 0.24606043100357056, R^2 Score: 0.227159321308136\n",
      "Epoch 60/200, Train Loss: 0.0489701887127012, Val Loss: 0.23689674586057663, R^2 Score: 0.2623634338378906\n",
      "Epoch 61/200, Train Loss: 0.053314597345888615, Val Loss: 0.21951018273830414, R^2 Score: 0.3112896680831909\n",
      "Epoch 62/200, Train Loss: 0.05152419750811532, Val Loss: 0.21358691155910492, R^2 Score: 0.3327200412750244\n",
      "Epoch 63/200, Train Loss: 0.05708878405857831, Val Loss: 0.2907752990722656, R^2 Score: 0.09197252988815308\n",
      "Epoch 64/200, Train Loss: 0.04317680455278605, Val Loss: 0.21572325378656387, R^2 Score: 0.3254271149635315\n",
      "Epoch 65/200, Train Loss: 0.0404666131362319, Val Loss: 0.24947122484445572, R^2 Score: 0.21814626455307007\n",
      "Epoch 66/200, Train Loss: 0.06075698393397033, Val Loss: 0.23887233436107635, R^2 Score: 0.2508915066719055\n",
      "Epoch 67/200, Train Loss: 0.04946794139686972, Val Loss: 0.23942645639181137, R^2 Score: 0.2494828701019287\n",
      "Epoch 68/200, Train Loss: 0.0740257550496608, Val Loss: 0.21885531395673752, R^2 Score: 0.3157687187194824\n",
      "Epoch 69/200, Train Loss: 0.04708872502669692, Val Loss: 0.30337678641080856, R^2 Score: 0.04449683427810669\n",
      "Epoch 70/200, Train Loss: 0.049175335094332695, Val Loss: 0.2337445542216301, R^2 Score: 0.27016621828079224\n",
      "Epoch 71/200, Train Loss: 0.07655877654906362, Val Loss: 0.22007650136947632, R^2 Score: 0.3126569986343384\n",
      "Epoch 72/200, Train Loss: 0.06724403414409608, Val Loss: 0.41449789702892303, R^2 Score: -0.29305851459503174\n",
      "Epoch 73/200, Train Loss: 0.056691626785323024, Val Loss: 0.2633151412010193, R^2 Score: 0.1780880093574524\n",
      "Epoch 74/200, Train Loss: 0.07516400550957769, Val Loss: 0.3234611600637436, R^2 Score: -0.01583564281463623\n",
      "Epoch 75/200, Train Loss: 0.052941429952625185, Val Loss: 0.23259034752845764, R^2 Score: 0.27107661962509155\n",
      "Epoch 76/200, Train Loss: 0.05652604531496763, Val Loss: 0.21689482778310776, R^2 Score: 0.32228267192840576\n",
      "Epoch 77/200, Train Loss: 0.05624596436973661, Val Loss: 0.24285710602998734, R^2 Score: 0.23724931478500366\n",
      "Epoch 78/200, Train Loss: 0.04406869289232418, Val Loss: 0.24325498938560486, R^2 Score: 0.24072492122650146\n",
      "Epoch 79/200, Train Loss: 0.03586747113149613, Val Loss: 0.25718795508146286, R^2 Score: 0.19538384675979614\n",
      "Epoch 80/200, Train Loss: 0.03885834850370884, Val Loss: 0.24657637625932693, R^2 Score: 0.22588402032852173\n",
      "Epoch 81/200, Train Loss: 0.032243704656139016, Val Loss: 0.21499284356832504, R^2 Score: 0.32728075981140137\n",
      "Epoch 82/200, Train Loss: 0.043990473728626966, Val Loss: 0.22548808157444, R^2 Score: 0.2930503487586975\n",
      "Epoch 83/200, Train Loss: 0.028080319694709033, Val Loss: 0.21406900137662888, R^2 Score: 0.32882159948349\n",
      "Epoch 84/200, Train Loss: 0.04713015980087221, Val Loss: 0.22065848112106323, R^2 Score: 0.3077129125595093\n",
      "Epoch 85/200, Train Loss: 0.04077643767232075, Val Loss: 0.21467987447977066, R^2 Score: 0.32652705907821655\n",
      "Epoch 86/200, Train Loss: 0.04171858308836818, Val Loss: 0.200651615858078, R^2 Score: 0.3709481358528137\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_86_val_0.2.pth\n",
      "Epoch 87/200, Train Loss: 0.042000492103397846, Val Loss: 0.2342371642589569, R^2 Score: 0.27005863189697266\n",
      "Epoch 88/200, Train Loss: 0.04234701709356159, Val Loss: 0.23364122956991196, R^2 Score: 0.26932114362716675\n",
      "Epoch 89/200, Train Loss: 0.04236805910477415, Val Loss: 0.24177680164575577, R^2 Score: 0.24083495140075684\n",
      "Epoch 90/200, Train Loss: 0.045980712107848376, Val Loss: 0.2396976724267006, R^2 Score: 0.2499268651008606\n",
      "Epoch 91/200, Train Loss: 0.05031124234665185, Val Loss: 0.2085784450173378, R^2 Score: 0.34702348709106445\n",
      "Epoch 92/200, Train Loss: 0.028040916076861322, Val Loss: 0.2028512880206108, R^2 Score: 0.36284399032592773\n",
      "Epoch 93/200, Train Loss: 0.04226204287260771, Val Loss: 0.2206227406859398, R^2 Score: 0.31057602167129517\n",
      "Epoch 94/200, Train Loss: 0.04037344525568187, Val Loss: 0.18542055040597916, R^2 Score: 0.4185643792152405\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_94_val_0.19.pth\n",
      "Epoch 95/200, Train Loss: 0.04983973246999085, Val Loss: 0.21963900327682495, R^2 Score: 0.30964815616607666\n",
      "Epoch 96/200, Train Loss: 0.039233875810168684, Val Loss: 0.25852689892053604, R^2 Score: 0.19188761711120605\n",
      "Epoch 97/200, Train Loss: 0.04331050388282165, Val Loss: 0.22447313368320465, R^2 Score: 0.294370174407959\n",
      "Epoch 98/200, Train Loss: 0.04735526174772531, Val Loss: 0.2269085869193077, R^2 Score: 0.2905771732330322\n",
      "Epoch 99/200, Train Loss: 0.06597436126321554, Val Loss: 0.23047738522291183, R^2 Score: 0.2779964208602905\n",
      "Epoch 100/200, Train Loss: 0.05227359745185822, Val Loss: 0.2632182911038399, R^2 Score: 0.17472606897354126\n",
      "Epoch 101/200, Train Loss: 0.05626035179011524, Val Loss: 0.34078502655029297, R^2 Score: -0.05888497829437256\n",
      "Epoch 102/200, Train Loss: 0.03712584311142564, Val Loss: 0.21689117699861526, R^2 Score: 0.3187715411186218\n",
      "Epoch 103/200, Train Loss: 0.032753357430920005, Val Loss: 0.219006709754467, R^2 Score: 0.31500929594039917\n",
      "Epoch 104/200, Train Loss: 0.05058456747792661, Val Loss: 0.20756827294826508, R^2 Score: 0.35138678550720215\n",
      "Epoch 105/200, Train Loss: 0.04005264461738989, Val Loss: 0.24028784781694412, R^2 Score: 0.24434828758239746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 12\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MedicalResNetModel(\n\u001b[0;32m      3\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m      4\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#pretrained=False\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\base_medical.py:145\u001b[0m, in \u001b[0;36mMedicalResNetModelBase.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m--> 145\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([value\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\meta_tensor.py:277\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m             ret\u001b[38;5;241m.\u001b[39mis_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, func, types, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wraps all torch functions.\"\"\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a model instance\n",
    "model = MedicalResNetModel(\n",
    "    num_epochs=200,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    data_loader=data_loader,\n",
    "    dropout_rate=0.1,\n",
    "    depth=34\n",
    "    #pretrained=False\n",
    ")\n",
    "\n",
    "# model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\n",
    "model.train()\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_487_height_384_epoch_34_val_0.13.pth, epoch: 34, val_loss: 0.12875201553106308\n",
      "R^2 score of the network on the test images: 0.37193775177001953\n",
      "Test Loss: 0.1726880818605423\n"
     ]
    }
   ],
   "source": [
    "# evaluate with the best model\n",
    "model.load_model('MedicalResNetModel_18_487_height_384_epoch_34_val_0.13.pth')\n",
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
