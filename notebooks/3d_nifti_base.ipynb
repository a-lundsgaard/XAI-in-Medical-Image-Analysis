{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "# make the module available from the src directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataLoaders.PatientDataLoader' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\dataLoaders\\\\PatientDataLoader.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataLoaders.PatientDataLoader import PatientDataProcessor\n",
    "importlib.reload(sys.modules['src.dataLoaders.PatientDataLoader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_folder = 'OAIData21/'\n",
    "data_path = '../datasets/meta_data/' + meta_folder\n",
    "visit = 0\n",
    "\n",
    "processor = PatientDataProcessor(base_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataLoaders.NiftiDataLoader2' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\dataLoaders\\\\NiftiDataLoader2.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataLoaders.NiftiDataLoader2 import NiftiDataLoader\n",
    "importlib.reload(sys.modules['src.dataLoaders.NiftiDataLoader2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.SliceTransformer import SliceAggregateTransform\n",
    "importlib.reload(sys.modules['src.transformers.SliceTransformer'])\n",
    "custom_transforms = [SliceAggregateTransform(keys=[\"image\"], slices=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V00: {'V00BMI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V01: {'P01BMI'}\n",
      "Missing columns for visit V02: {'V02PASE', 'V02BMI', 'P01BMI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V03: {'P01BMI'}\n",
      "Missing columns for visit V04: {'V04BMI', 'V04PASE', 'P01BMI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V05: {'P01BMI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V06: {'P01BMI'}\n",
      "Missing columns for visit V07: {'V07BMI', 'P01BMI', 'V07PASE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V08: {'P01BMI'}\n",
      "Missing columns for visit V09: {'V09PASE', 'V09BMI', 'P01BMI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V10: {'P01BMI'}\n",
      "Missing columns for visit V11: {'V11PASE', 'V11BMI', 'P01BMI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:105: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.enroll_df = df_enroll[['P02SEX']].replace(\n",
      "c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\PatientDataLoader.py:153: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframe[column].fillna(mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
      "Total images detected: 8876\n",
      "Total images: [{'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9000798-Left-V00.nii.gz', 'label': 8.0}, {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9000798-Right-V00.nii.gz', 'label': 0.0}, {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9001695-Left-V00.nii.gz', 'label': 0.0}, {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9001695-Right-V00.nii.gz', 'label': 0.0}, {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9001897-Left-V00.nii.gz', 'label': 0.0}]\n",
      "Example train data: {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9082159-Right-V00.nii.gz', 'label': 13.0}\n",
      "Example validation data: {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9229496-Right-V05.nii.gz', 'label': 3.0}\n",
      "Example test data: {'image': 'C:/Users/askel/Downloads/NIFTY/NIFTY/9622390-Left-V03.nii.gz', 'label': 1.0}\n",
      "Cache num: 6212\n",
      "Cache num: 440\n",
      "Cache num: 880\n"
     ]
    }
   ],
   "source": [
    "dataset = 'niftiShort'\n",
    "data_path = '../datasets/nifti/'\n",
    "data_dir = f'{data_path}{dataset}'\n",
    "\n",
    "data_dir = 'C:/Users/askel/Downloads/NIFTY/NIFTY/'\n",
    "\n",
    "data_loader = NiftiDataLoader(data_dir=data_dir, \n",
    "                              meta_data_loader=processor, \n",
    "                              batch_size=32,\n",
    "                              spatial_size=(256, 256, 256),\n",
    "                              cache_rate=0.5, \n",
    "                              replace_rate=1, \n",
    "                              custom_transforms=custom_transforms,\n",
    "                              )\n",
    "# data_loader.load_data(visit_no=visit, subset_size=2058, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=84, cache=\"standard\")\n",
    "#data_loader.load_data(subset_size=4400, cache=\"standard\")\n",
    "data_loader.load_data(subset_size=8800, cache=\"persistent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models.medical_models.monai_resnet' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\models\\\\medical_models\\\\monai_resnet.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.models.baseModels.resnet_3D_monai import MedicalResNetModel\n",
    "# importlib.reload(sys.modules['src.models.baseModels.resnet_3D_monai'])\n",
    "\n",
    "from src.models.medical_models.medical_resnet import MedicalResNetModel\n",
    "importlib.reload(sys.modules['src.models.medical_models.base_medical'])\n",
    "importlib.reload(sys.modules['src.models.medical_models.medical_resnet'])\n",
    "\n",
    "\n",
    "from src.models.medical_models.monai_resnet import MonaiMedicalResNet\n",
    "importlib.reload(sys.modules['src.models.medical_models.monai_resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image spatial dimensions:  2\n",
      "Number of input channels:  3\n",
      "gpu:  cuda:0\n",
      "Model and optimizer state loaded from 'c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_6212_epoch_38.pth'\n",
      "Is cuda available:  True cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-622 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 2.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.44755558111728766, Val Loss: 8.425697735377721\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_6212_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-632 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 3.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 5.719360050788293, Val Loss: 8.68039846420288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-642 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 1.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 5.7661489095443335, Val Loss: 8.341435773032051\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_6212_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-652 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 1.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 0.9324468686030462, Val Loss: 8.948773894991193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-662 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 3.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 2.582822028184548, Val Loss: 10.527145998818535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-672 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 1.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 5.438475662622697, Val Loss: 9.209067072187151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-682 (enqueue_values):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\thread_buffer.py\", line 49, in enqueue_values\n",
      "    for src_val in self.src:\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 3.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 141, in apply_transform\n",
      "    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 98, in _apply_transform\n",
      "    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n",
      "                                                                               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\dictionary.py\", line 162, in __call__\n",
      "    data = self._loader(d[key], reader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\io\\array.py\", line 282, in __call__\n",
      "    img_array, meta_data = reader.get_data(img)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 938, in get_data\n",
      "    data = self._get_array_data(i)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\image_reader.py\", line 1012, in _get_array_data\n",
      "    return np.asanyarray(img.dataobj, order=\"C\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 457, in __array__\n",
      "    arr = self._get_scaled(dtype=dtype, slicer=())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 424, in _get_scaled\n",
      "    scaled = apply_read_scaling(self._get_unscaled(slicer=slicer), scl_slope, scl_inter)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\arrayproxy.py\", line 394, in _get_unscaled\n",
      "    return array_from_file(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\nibabel\\volumeutils.py\", line 472, in array_from_file\n",
      "    raise OSError(\n",
      "OSError: Expected 47185920 bytes, got 37158912 bytes from \n",
      " - could the file be damaged?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 112, in __getitem__\n",
      "    return self._transform(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 418, in _transform\n",
      "    pre_random_item = self._cachecheck(self.data[index])\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 391, in _cachecheck\n",
      "    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\dataset.py\", line 332, in _pre_transform\n",
      "    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 335, in __call__\n",
      "    result = execute_compose(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\compose.py\", line 111, in execute_compose\n",
      "    data = apply_transform(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\transforms\\transform.py\", line 171, in apply_transform\n",
      "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
      "RuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x000001BA155DAB10>\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MedicalResNetModel(\n\u001b[0;32m      3\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      4\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#pretrained=False\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedicalResNetModel_18_6212_epoch_38.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\base_medical.py:146\u001b[0m, in \u001b[0;36mMedicalResNetModelBase.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Compute validation loss once per epoch\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m current_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Print epoch statistics\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader\u001b[38;5;241m.\u001b[39mtrain_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\base_medical.py:117\u001b[0m, in \u001b[0;36mMedicalResNetModelBase.validation_loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    116\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m--> 117\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    119\u001b[0m average_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m count \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a model instance\n",
    "model = MedicalResNetModel(\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    data_loader=data_loader,\n",
    "    #dropout_rate=0.1,\n",
    "    #pretrained=False\n",
    ")\n",
    "\n",
    "model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\n",
    "model.train()\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with the best model\n",
    "# model.load_model('MedicalResNetModel_18_4400_epoch_16.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
