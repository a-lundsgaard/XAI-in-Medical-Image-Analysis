{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "# make the module available from the src directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataLoaders.PatientDataLoader' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\dataLoaders\\\\PatientDataLoader.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataLoaders.PatientDataLoader import PatientDataProcessor\n",
    "importlib.reload(sys.modules['src.dataLoaders.PatientDataLoader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns for visit V00: {'V00KOOSL', 'V00KOOSR'}\n",
      "Missing columns for visit V01: {'V01KOOSL', 'V01KOOSR'}\n",
      "Missing columns for visit V02: {'V02KOOSR', 'V02KOOSL'}\n",
      "Missing columns for visit V03: {'V03KOOSL', 'V03KOOSR'}\n",
      "Missing columns for visit V04: {'V04KOOSR', 'V04KOOSL'}\n",
      "Missing columns for visit V05: {'V05KOOSR', 'V05KOOSL'}\n",
      "Missing columns for visit V06: {'V06KOOSL', 'V06KOOSR'}\n",
      "Missing columns for visit V07: {'V07KOOSL', 'V07KOOSR'}\n",
      "Missing columns for visit V08: {'V08KOOSL', 'V08KOOSR'}\n",
      "Missing columns for visit V09: {'V09KOOSL', 'V09KOOSR'}\n",
      "Missing columns for visit V10: {'V10KOOSR', 'V10KOOSL'}\n",
      "Missing columns for visit V11: {'V11KOOSL', 'V11KOOSR'}\n"
     ]
    }
   ],
   "source": [
    "meta_folder = 'OAIData21/'\n",
    "data_path = '../datasets/meta_data/' + meta_folder\n",
    "\n",
    "processor = PatientDataProcessor(base_path=data_path)\n",
    "meta_data = processor.load_all_clinical_data(labels=[\"KOOSKP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V00AGE</th>\n",
       "      <th>V00WOMKPL</th>\n",
       "      <th>V00WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V01AGE</th>\n",
       "      <th>V01WOMKPL</th>\n",
       "      <th>V01WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V02AGE</th>\n",
       "      <th>V02WOMKPL</th>\n",
       "      <th>...</th>\n",
       "      <th>V09WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V10AGE</th>\n",
       "      <th>V10WOMKPL</th>\n",
       "      <th>V10WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "      <th>V11AGE</th>\n",
       "      <th>V11WOMKPL</th>\n",
       "      <th>V11WOMKPR</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9000099</th>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000296</th>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000622</th>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000798</th>\n",
       "      <td>56</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9001104</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999365</th>\n",
       "      <td>56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999510</th>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999862</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999865</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999878</th>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4796 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V00AGE  V00WOMKPL  V00WOMKPR  Sex  V01AGE  V01WOMKPL  V01WOMKPR  Sex  \\\n",
       "ID                                                                              \n",
       "9000099      59        0.0        1.0    0    60.0        0.0        0.0    0   \n",
       "9000296      69        0.0        0.0    0    70.0        0.0        0.0    0   \n",
       "9000622      71        0.0        3.0    1    72.0        0.0        2.0    1   \n",
       "9000798      56        8.0        0.0    0    58.0        8.0        0.0    0   \n",
       "9001104      72        0.0        4.0    1    73.0        0.0        1.0    1   \n",
       "...         ...        ...        ...  ...     ...        ...        ...  ...   \n",
       "9999365      56        4.0        5.0    0    57.0        3.0        5.0    0   \n",
       "9999510      50        3.0        0.0    0    51.0        1.0        0.0    0   \n",
       "9999862      61        0.0        0.0    1    62.0        0.0        0.0    1   \n",
       "9999865      61        0.0        0.0    1    62.0        0.0        0.0    1   \n",
       "9999878      72        1.0        1.0    1    73.0        1.0        0.0    1   \n",
       "\n",
       "         V02AGE  V02WOMKPL  ...  V09WOMKPR  Sex  V10AGE  V10WOMKPL  V10WOMKPR  \\\n",
       "ID                          ...                                                 \n",
       "9000099     NaN        NaN  ...        0.0    0    66.0        4.0        3.0   \n",
       "9000296     NaN        NaN  ...        0.0    0    77.0        0.0        0.0   \n",
       "9000622     NaN        NaN  ...               1     NaN        NaN        NaN   \n",
       "9000798    58.0        7.0  ...        0.0    0    64.0        5.0        0.0   \n",
       "9001104     NaN        NaN  ...               1    80.0        0.0        1.0   \n",
       "...         ...        ...  ...        ...  ...     ...        ...        ...   \n",
       "9999365     NaN        NaN  ...        1.0    0    64.0        4.0        2.0   \n",
       "9999510     NaN        NaN  ...        1.0    0    58.0        3.0        0.0   \n",
       "9999862     NaN        NaN  ...        0.0    1    69.0        0.0        0.0   \n",
       "9999865     NaN        NaN  ...        0.0    1    69.0        3.0        1.0   \n",
       "9999878     NaN        NaN  ...        0.0    1    79.0        1.0        1.0   \n",
       "\n",
       "         Sex  V11AGE  V11WOMKPL  V11WOMKPR  Sex  \n",
       "ID                                               \n",
       "9000099    0    67.0        4.0        2.0    0  \n",
       "9000296    0    78.0        0.0        0.0    0  \n",
       "9000622    1     NaN        NaN        NaN    1  \n",
       "9000798    0    65.0        3.0        0.0    0  \n",
       "9001104    1     NaN        NaN        NaN    1  \n",
       "...      ...     ...        ...        ...  ...  \n",
       "9999365    0    65.0        5.0        6.0    0  \n",
       "9999510    0    59.0        4.0        0.0    0  \n",
       "9999862    1    70.0        0.0        0.0    1  \n",
       "9999865    1    70.0        0.0        0.0    1  \n",
       "9999878    1    80.0        2.0        1.0    1  \n",
       "\n",
       "[4796 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataLoaders.utils.BalancedDataLoader import BalancedBatchSampler\n",
    "importlib.reload(sys.modules['src.dataLoaders.utils.BalancedDataLoader'])\n",
    "\n",
    "from src.dataLoaders.NiftiDataLoader2 import NiftiDataLoader\n",
    "importlib.reload(sys.modules['src.dataLoaders.NiftiDataLoader2'])\n",
    "\n",
    "from src.transformers.SliceTransformer import SliceAggregateTransform\n",
    "importlib.reload(sys.modules['src.transformers.SliceTransformer'])\n",
    "custom_transforms = [SliceAggregateTransform(keys=[\"image\"], slices=9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\saved_data_lists\\data_list.pkl does not exist.\n",
      "Data list loaded: False\n",
      "Using custom sampler: False\n",
      "File c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\dataLoaders\\saved_data_lists\\data_list.pkl does not exist.\n",
      "Visits: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
      "Total images detected: 8871\n",
      "Subset size: 3000\n",
      "Cache num: 3000\n",
      "Cache num: 300\n",
      "Cache num: 300\n",
      "batch_size: 32\n"
     ]
    }
   ],
   "source": [
    "dataset = 'niftiShort'\n",
    "data_path = '../datasets/nifti/'\n",
    "data_dir = f'{data_path}{dataset}'\n",
    "\n",
    "\n",
    "\n",
    "# data_dir = 'C:/Users/askel/Downloads/NIFTY/NIFTY/'\n",
    "# max = 8876\n",
    "dim = 128\n",
    "data_loader = NiftiDataLoader(data_dir=data_dir, \n",
    "                              meta_data_loader=processor,\n",
    "                              batch_size=32,\n",
    "                              spatial_resize=(dim, dim, dim),\n",
    "                              cache_rate=0.5, \n",
    "                              replace_rate=1, \n",
    "                              custom_transforms=custom_transforms,\n",
    "                              custom_sampler=False,\n",
    "                              )\n",
    "# data_loader.load_data(visit_no=visit, subset_size=2058, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=84, cache=\"standard\")\n",
    "#data_loader.load_data(subset_size=4400, cache=\"standard\")\n",
    "# data_loader.load_data(subset_size=8875, cache=\"standard\")\n",
    "data_loader.load_data(cache=\"persistent\", subset_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models.medical_models.monai_resnet' from 'c:\\\\Datalogi\\\\Bachelor\\\\XAI-in-Medical-Image-Analysis\\\\src\\\\models\\\\medical_models\\\\monai_resnet.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.models.baseModels.resnet_3D_monai import MedicalResNetModel\n",
    "# importlib.reload(sys.modules['src.models.baseModels.resnet_3D_monai'])\n",
    "\n",
    "from src.models.medical_models.medical_resnet import MedicalResNetModel\n",
    "importlib.reload(sys.modules['src.models.medical_models.base_medical'])\n",
    "importlib.reload(sys.modules['src.models.medical_models.medical_resnet'])\n",
    "\n",
    "\n",
    "from src.models.medical_models.monai_resnet import MonaiMedicalResNet\n",
    "importlib.reload(sys.modules['src.models.medical_models.monai_resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader.train_loader.dataset[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader train loader:  94 3000\n",
      "Image spatial dimensions:  torch.Size([32, 9, 384, 384])\n",
      "Number of input channels:  9\n",
      "gpu:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create a model instance\n",
    "fast_model = MedicalResNetModel(\n",
    "    num_epochs=300,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    data_loader=data_loader,\n",
    "    dropout_rate=0.1,\n",
    "    depth=18\n",
    "    #pretrained=False\n",
    ")\n",
    "\n",
    "# model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\n",
    "# fast_model.train()\n",
    "# fast_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader train loader:  94 3000\n",
      "Image spatial dimensions:  torch.Size([32, 9, 384, 384])\n",
      "Number of input channels:  9\n",
      "gpu:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create a model instance\n",
    "sample_model = MedicalResNetModel(\n",
    "    num_epochs=300,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    data_loader=data_loader,\n",
    "    dropout_rate=0.1,\n",
    "    depth=18\n",
    "    #pretrained=False\n",
    ")\n",
    "\n",
    "# model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\n",
    "# sample_model.train()\n",
    "# sample_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader train loader:  94 3000\n",
      "Image spatial dimensions:  torch.Size([32, 9, 384, 384])\n",
      "Number of input channels:  9\n",
      "gpu:  cuda:0\n",
      "Is cuda available:  True cuda\n",
      "Number of training images: 3000\n",
      "Epoch 1/300, Train Loss: 10.29667071078686, Val Loss: 10.349237394332885, R^2 Score: -0.00307619571685791\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_1_val_10.35_r2_10.35.pth\n",
      "Epoch 2/300, Train Loss: 9.663111473651643, Val Loss: 10.193795204162598, R^2 Score: 0.003748774528503418\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_2_val_10.19_r2_10.19.pth\n",
      "Epoch 3/300, Train Loss: 9.657477485372665, Val Loss: 9.800292348861694, R^2 Score: 0.04393666982650757\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_3_val_9.8_r2_9.8.pth\n",
      "Epoch 4/300, Train Loss: 9.506504477338588, Val Loss: 10.145402336120606, R^2 Score: 0.008724093437194824\n",
      "Epoch 5/300, Train Loss: 9.49513843211722, Val Loss: 10.064473581314086, R^2 Score: 0.01727527379989624\n",
      "Epoch 6/300, Train Loss: 9.347321936424743, Val Loss: 9.69886565208435, R^2 Score: 0.05124008655548096\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_6_val_9.7_r2_9.7.pth\n",
      "Epoch 7/300, Train Loss: 9.258997394683513, Val Loss: 12.946220684051514, R^2 Score: -0.2711995840072632\n",
      "Epoch 8/300, Train Loss: 9.369394951678338, Val Loss: 9.89929165840149, R^2 Score: 0.03276515007019043\n",
      "Epoch 9/300, Train Loss: 9.51600342101239, Val Loss: 9.844365882873536, R^2 Score: 0.03197139501571655\n",
      "Epoch 10/300, Train Loss: 9.281399884122484, Val Loss: 10.532147312164307, R^2 Score: -0.037572503089904785\n",
      "Epoch 11/300, Train Loss: 9.286208949190504, Val Loss: 9.853767490386963, R^2 Score: 0.03746771812438965\n",
      "Epoch 12/300, Train Loss: 9.149031748162939, Val Loss: 12.019904518127442, R^2 Score: -0.1674128770828247\n",
      "Epoch 13/300, Train Loss: 9.13041153867194, Val Loss: 9.78354878425598, R^2 Score: 0.03814953565597534\n",
      "Epoch 14/300, Train Loss: 9.127014583729682, Val Loss: 10.017749118804932, R^2 Score: 0.017998814582824707\n",
      "Epoch 15/300, Train Loss: 8.987960726656812, Val Loss: 10.652953052520752, R^2 Score: -0.03796076774597168\n",
      "Epoch 16/300, Train Loss: 8.81582708561674, Val Loss: 14.273647785186768, R^2 Score: -0.3728482723236084\n",
      "Epoch 17/300, Train Loss: 8.665205318877037, Val Loss: 9.531183099746704, R^2 Score: 0.06750500202178955\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_17_val_9.53_r2_9.53.pth\n",
      "Epoch 18/300, Train Loss: 8.658192971919446, Val Loss: 9.258365154266357, R^2 Score: 0.09748786687850952\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_18_val_9.26_r2_9.26.pth\n",
      "Epoch 19/300, Train Loss: 8.40592894401956, Val Loss: 9.106482028961182, R^2 Score: 0.11713284254074097\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_19_val_9.11_r2_9.11.pth\n",
      "Epoch 20/300, Train Loss: 8.187486843859896, Val Loss: 8.863956928253174, R^2 Score: 0.13321375846862793\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_20_val_8.86_r2_8.86.pth\n",
      "Epoch 21/300, Train Loss: 8.125927001871961, Val Loss: 10.492146539688111, R^2 Score: -0.026131272315979004\n",
      "Epoch 22/300, Train Loss: 7.905229368108384, Val Loss: 9.178452730178833, R^2 Score: 0.12307268381118774\n",
      "Epoch 23/300, Train Loss: 7.911569567436867, Val Loss: 8.649816226959228, R^2 Score: 0.17068403959274292\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_23_val_8.65_r2_8.65.pth\n",
      "Epoch 24/300, Train Loss: 7.569065644385967, Val Loss: 8.335729169845582, R^2 Score: 0.1868545413017273\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_3000_height_384_epoch_24_val_8.34_r2_8.34.pth\n",
      "Epoch 25/300, Train Loss: 7.218781920189553, Val Loss: 9.814098882675172, R^2 Score: 0.03673374652862549\n",
      "Epoch 26/300, Train Loss: 7.25861354077116, Val Loss: 8.561508274078369, R^2 Score: 0.17000770568847656\n",
      "Epoch 27/300, Train Loss: 6.831067239984553, Val Loss: 11.149242973327636, R^2 Score: -0.05682241916656494\n",
      "Epoch 28/300, Train Loss: 6.507031075497891, Val Loss: 8.771226263046264, R^2 Score: 0.1627432107925415\n",
      "Epoch 29/300, Train Loss: 5.7203531341349825, Val Loss: 9.826880693435669, R^2 Score: 0.03475457429885864\n",
      "Epoch 30/300, Train Loss: 5.502520165544875, Val Loss: 9.233553552627564, R^2 Score: 0.09021693468093872\n",
      "Epoch 31/300, Train Loss: 4.643828526456305, Val Loss: 10.016270017623901, R^2 Score: 0.06618368625640869\n",
      "Epoch 32/300, Train Loss: 4.101254477145824, Val Loss: 9.61213526725769, R^2 Score: 0.05258435010910034\n",
      "Epoch 33/300, Train Loss: 3.172967019233298, Val Loss: 11.073994445800782, R^2 Score: -0.06891405582427979\n",
      "Epoch 34/300, Train Loss: 2.681035445725664, Val Loss: 9.839928388595581, R^2 Score: 0.06061899662017822\n",
      "Epoch 35/300, Train Loss: 2.083811565916589, Val Loss: 9.366457462310791, R^2 Score: 0.09036070108413696\n",
      "Epoch 36/300, Train Loss: 1.7103153143791443, Val Loss: 9.608172798156739, R^2 Score: 0.05388444662094116\n",
      "Epoch 37/300, Train Loss: 1.4587881977253772, Val Loss: 10.586018228530884, R^2 Score: -0.03397059440612793\n",
      "Epoch 38/300, Train Loss: 1.2918727711794225, Val Loss: 9.543741703033447, R^2 Score: 0.08059996366500854\n",
      "Epoch 39/300, Train Loss: 1.0490980474872793, Val Loss: 9.34919638633728, R^2 Score: 0.09785515069961548\n",
      "Epoch 40/300, Train Loss: 1.0972665608563321, Val Loss: 9.358089685440063, R^2 Score: 0.10236066579818726\n",
      "Epoch 41/300, Train Loss: 1.0484319367307298, Val Loss: 9.491638326644898, R^2 Score: 0.07913249731063843\n",
      "Epoch 42/300, Train Loss: 1.0239819145583091, Val Loss: 9.666553974151611, R^2 Score: 0.0661780834197998\n",
      "Epoch 43/300, Train Loss: 0.9238448759659807, Val Loss: 10.247969961166381, R^2 Score: -0.0025887489318847656\n",
      "Epoch 44/300, Train Loss: 0.8621709183492559, Val Loss: 9.744160270690918, R^2 Score: 0.060882508754730225\n",
      "Epoch 45/300, Train Loss: 0.9758270940882094, Val Loss: 9.768043518066406, R^2 Score: 0.055719614028930664\n",
      "Epoch 46/300, Train Loss: 0.9519841728058267, Val Loss: 9.18051176071167, R^2 Score: 0.11162114143371582\n",
      "Epoch 47/300, Train Loss: 0.9019326761047891, Val Loss: 10.250391864776612, R^2 Score: 0.02435922622680664\n",
      "Epoch 48/300, Train Loss: 0.8601357363005901, Val Loss: 9.262343645095825, R^2 Score: 0.1136675477027893\n",
      "Epoch 49/300, Train Loss: 0.8063874717088456, Val Loss: 9.960365104675294, R^2 Score: 0.035109877586364746\n",
      "Epoch 50/300, Train Loss: 0.8601542581269082, Val Loss: 9.574306344985962, R^2 Score: 0.07993656396865845\n",
      "Epoch 51/300, Train Loss: 0.8440892525175785, Val Loss: 9.226612329483032, R^2 Score: 0.10656553506851196\n",
      "Epoch 52/300, Train Loss: 0.754484659338251, Val Loss: 8.872698879241943, R^2 Score: 0.15051811933517456\n",
      "Epoch 53/300, Train Loss: 0.8019412262959683, Val Loss: 9.901699876785278, R^2 Score: 0.056802570819854736\n",
      "Epoch 54/300, Train Loss: 0.701645628568974, Val Loss: 9.216773748397827, R^2 Score: 0.12397950887680054\n",
      "Epoch 55/300, Train Loss: 0.7270391994017236, Val Loss: 9.005982685089112, R^2 Score: 0.13929420709609985\n",
      "Epoch 56/300, Train Loss: 0.7479625926055806, Val Loss: 9.57981481552124, R^2 Score: 0.08486747741699219\n",
      "Epoch 57/300, Train Loss: 0.7557526982211052, Val Loss: 9.753944492340088, R^2 Score: 0.06602799892425537\n",
      "Epoch 58/300, Train Loss: 0.8160162805876834, Val Loss: 9.829490089416504, R^2 Score: 0.05291706323623657\n",
      "Epoch 59/300, Train Loss: 0.9263951867184741, Val Loss: 9.745522785186768, R^2 Score: 0.05989140272140503\n",
      "Epoch 60/300, Train Loss: 0.7662728393965579, Val Loss: 9.373995304107666, R^2 Score: 0.10769402980804443\n",
      "Epoch 61/300, Train Loss: 0.7154716484724207, Val Loss: 9.526902675628662, R^2 Score: 0.08467870950698853\n",
      "Epoch 62/300, Train Loss: 0.7775495981282377, Val Loss: 9.998459434509277, R^2 Score: 0.02650552988052368\n",
      "Epoch 63/300, Train Loss: 0.7178131165973684, Val Loss: 9.178801584243775, R^2 Score: 0.10611164569854736\n",
      "Epoch 64/300, Train Loss: 0.6682440966684767, Val Loss: 9.210983085632325, R^2 Score: 0.1088259220123291\n",
      "Epoch 65/300, Train Loss: 0.6720706722203721, Val Loss: 9.531956434249878, R^2 Score: 0.09217023849487305\n",
      "Epoch 66/300, Train Loss: 0.6901137305701033, Val Loss: 9.120641922950744, R^2 Score: 0.11499011516571045\n",
      "Epoch 67/300, Train Loss: 0.5956863190265412, Val Loss: 8.983940172195435, R^2 Score: 0.13987523317337036\n",
      "Epoch 68/300, Train Loss: 0.6486699687356644, Val Loss: 9.2126455783844, R^2 Score: 0.11106729507446289\n",
      "Epoch 69/300, Train Loss: 0.6124006241877028, Val Loss: 8.851710748672485, R^2 Score: 0.15206408500671387\n",
      "Epoch 70/300, Train Loss: 0.5107010239933399, Val Loss: 8.763098001480103, R^2 Score: 0.15981197357177734\n",
      "Epoch 71/300, Train Loss: 0.5610186468730581, Val Loss: 9.140418767929077, R^2 Score: 0.12484019994735718\n",
      "Epoch 72/300, Train Loss: 0.5006640420315114, Val Loss: 9.030787754058839, R^2 Score: 0.12110579013824463\n",
      "Epoch 73/300, Train Loss: 0.47350112776807013, Val Loss: 8.791985034942627, R^2 Score: 0.15644872188568115\n",
      "Epoch 74/300, Train Loss: 0.48077221151362076, Val Loss: 8.937893199920655, R^2 Score: 0.14528560638427734\n",
      "Epoch 75/300, Train Loss: 0.5392825578121428, Val Loss: 9.064840650558471, R^2 Score: 0.12690627574920654\n",
      "Epoch 76/300, Train Loss: 0.5660546136663315, Val Loss: 8.840106296539307, R^2 Score: 0.1477799415588379\n",
      "Epoch 77/300, Train Loss: 0.5377517344152674, Val Loss: 8.988498544692993, R^2 Score: 0.1381092667579651\n",
      "Epoch 78/300, Train Loss: 0.5268744196980557, Val Loss: 8.658882474899292, R^2 Score: 0.17209380865097046\n",
      "Epoch 79/300, Train Loss: 0.5203167561520922, Val Loss: 9.060404968261718, R^2 Score: 0.12931489944458008\n",
      "Epoch 80/300, Train Loss: 0.5870273003869868, Val Loss: 9.017537450790405, R^2 Score: 0.13899075984954834\n",
      "Epoch 81/300, Train Loss: 0.4307993361131942, Val Loss: 8.9556480884552, R^2 Score: 0.13423246145248413\n",
      "Epoch 82/300, Train Loss: 0.44018018752970595, Val Loss: 8.695068502426148, R^2 Score: 0.16684579849243164\n",
      "Epoch 83/300, Train Loss: 0.5010073733456591, Val Loss: 8.977869749069214, R^2 Score: 0.1300029158592224\n",
      "Epoch 84/300, Train Loss: 0.4943312273380604, Val Loss: 8.853572750091553, R^2 Score: 0.1519889235496521\n",
      "Epoch 85/300, Train Loss: 0.5296644633437725, Val Loss: 10.022702932357788, R^2 Score: 0.033416748046875\n",
      "Epoch 86/300, Train Loss: 0.47277636508992377, Val Loss: 8.930790996551513, R^2 Score: 0.14045405387878418\n",
      "Epoch 87/300, Train Loss: 0.43801273468961105, Val Loss: 9.034178829193115, R^2 Score: 0.13163572549819946\n",
      "Epoch 88/300, Train Loss: 0.4390654849245193, Val Loss: 8.95231122970581, R^2 Score: 0.14745426177978516\n",
      "Epoch 89/300, Train Loss: 0.4492534324526787, Val Loss: 9.399610233306884, R^2 Score: 0.09190905094146729\n",
      "Epoch 90/300, Train Loss: 0.45127324347800396, Val Loss: 9.01681604385376, R^2 Score: 0.1271076798439026\n",
      "Epoch 91/300, Train Loss: 0.4957860464111288, Val Loss: 8.887981939315797, R^2 Score: 0.14609766006469727\n",
      "Epoch 92/300, Train Loss: 0.42516904181622445, Val Loss: 9.07666745185852, R^2 Score: 0.13488346338272095\n",
      "Epoch 93/300, Train Loss: 0.3783910778608728, Val Loss: 9.004988718032838, R^2 Score: 0.13544440269470215\n",
      "Epoch 94/300, Train Loss: 0.37097868442218357, Val Loss: 8.945317792892457, R^2 Score: 0.14023208618164062\n",
      "Epoch 95/300, Train Loss: 0.34625609821461617, Val Loss: 8.749910068511962, R^2 Score: 0.16073554754257202\n",
      "Epoch 96/300, Train Loss: 0.3550593169762733, Val Loss: 9.011740446090698, R^2 Score: 0.13199502229690552\n",
      "Epoch 97/300, Train Loss: 0.3694254567331456, Val Loss: 9.157056260108948, R^2 Score: 0.11537563800811768\n",
      "Epoch 98/300, Train Loss: 0.35845900976911504, Val Loss: 9.068490934371948, R^2 Score: 0.12053853273391724\n",
      "Epoch 99/300, Train Loss: 0.37251976829894046, Val Loss: 9.075113344192506, R^2 Score: 0.13001024723052979\n",
      "Epoch 100/300, Train Loss: 0.3699664790579613, Val Loss: 8.968721103668212, R^2 Score: 0.1377754807472229\n",
      "Epoch 101/300, Train Loss: 0.3819541374736644, Val Loss: 9.475396156311035, R^2 Score: 0.08748066425323486\n",
      "Epoch 102/300, Train Loss: 0.4236116019335199, Val Loss: 9.389413261413575, R^2 Score: 0.08865386247634888\n",
      "Epoch 103/300, Train Loss: 0.4540209654480853, Val Loss: 9.80251441001892, R^2 Score: 0.044679880142211914\n",
      "Epoch 104/300, Train Loss: 0.4005042596700344, Val Loss: 9.186459493637084, R^2 Score: 0.12133383750915527\n",
      "Epoch 105/300, Train Loss: 0.36529913576359446, Val Loss: 9.100706768035888, R^2 Score: 0.12144458293914795\n",
      "Epoch 106/300, Train Loss: 0.39872796246980097, Val Loss: 8.936584663391113, R^2 Score: 0.132698655128479\n",
      "Epoch 107/300, Train Loss: 0.3647148694763792, Val Loss: 9.021402931213379, R^2 Score: 0.13448137044906616\n",
      "Epoch 108/300, Train Loss: 0.39946520201703334, Val Loss: 9.077291297912598, R^2 Score: 0.11849361658096313\n",
      "Epoch 109/300, Train Loss: 0.4369211547235225, Val Loss: 9.314884328842163, R^2 Score: 0.10722541809082031\n",
      "Epoch 110/300, Train Loss: 0.33285755061722816, Val Loss: 9.462401819229125, R^2 Score: 0.08647441864013672\n",
      "Epoch 111/300, Train Loss: 0.26324159105090383, Val Loss: 9.01116304397583, R^2 Score: 0.12724530696868896\n",
      "Epoch 112/300, Train Loss: 0.2421261120508326, Val Loss: 9.122754859924317, R^2 Score: 0.1213536262512207\n",
      "Epoch 113/300, Train Loss: 0.2561255497263467, Val Loss: 9.178492212295533, R^2 Score: 0.12104165554046631\n",
      "Epoch 114/300, Train Loss: 0.2696201517543894, Val Loss: 9.167647981643677, R^2 Score: 0.11328703165054321\n",
      "Epoch 115/300, Train Loss: 0.266846266912019, Val Loss: 9.166753482818603, R^2 Score: 0.11710071563720703\n",
      "Epoch 116/300, Train Loss: 0.23590164924872684, Val Loss: 9.736474990844727, R^2 Score: 0.057704925537109375\n",
      "Epoch 117/300, Train Loss: 0.22255544507123054, Val Loss: 8.930304098129273, R^2 Score: 0.13862788677215576\n",
      "Epoch 118/300, Train Loss: 0.2482954926313238, Val Loss: 8.98443832397461, R^2 Score: 0.1375754475593567\n",
      "Epoch 119/300, Train Loss: 0.25468833871344304, Val Loss: 8.850903654098511, R^2 Score: 0.14556431770324707\n",
      "Epoch 120/300, Train Loss: 0.2740671748018011, Val Loss: 8.853629064559936, R^2 Score: 0.14769971370697021\n",
      "Epoch 121/300, Train Loss: 0.3916149007830214, Val Loss: 9.07492094039917, R^2 Score: 0.12864434719085693\n",
      "Epoch 122/300, Train Loss: 0.41761610672828997, Val Loss: 9.108995532989502, R^2 Score: 0.12509006261825562\n",
      "Epoch 123/300, Train Loss: 0.38490518626380477, Val Loss: 8.88720245361328, R^2 Score: 0.14496469497680664\n",
      "Epoch 124/300, Train Loss: 0.40227955698649936, Val Loss: 8.38177490234375, R^2 Score: 0.18741029500961304\n",
      "Epoch 125/300, Train Loss: 0.3098662484516489, Val Loss: 8.898129796981811, R^2 Score: 0.15284180641174316\n",
      "Epoch 126/300, Train Loss: 0.2531307625802273, Val Loss: 9.578240585327148, R^2 Score: 0.07040321826934814\n",
      "Epoch 127/300, Train Loss: 0.271541565656662, Val Loss: 8.426078844070435, R^2 Score: 0.19579094648361206\n",
      "Epoch 128/300, Train Loss: 0.200275211020353, Val Loss: 8.843417978286743, R^2 Score: 0.15850883722305298\n",
      "Epoch 129/300, Train Loss: 0.19359444347309304, Val Loss: 8.603865957260131, R^2 Score: 0.17286908626556396\n",
      "Epoch 130/300, Train Loss: 0.1625107122149239, Val Loss: 8.658701419830322, R^2 Score: 0.16912943124771118\n",
      "Epoch 131/300, Train Loss: 0.17298586619027118, Val Loss: 8.71413745880127, R^2 Score: 0.1607779860496521\n",
      "Epoch 132/300, Train Loss: 0.16375452494050594, Val Loss: 8.95146267414093, R^2 Score: 0.12808752059936523\n",
      "Epoch 133/300, Train Loss: 0.1962816347070831, Val Loss: 9.016721153259278, R^2 Score: 0.13990074396133423\n",
      "Epoch 134/300, Train Loss: 0.20642703454545203, Val Loss: 8.834918546676636, R^2 Score: 0.1494085192680359\n",
      "Epoch 135/300, Train Loss: 0.17749314406450759, Val Loss: 9.002262234687805, R^2 Score: 0.12788236141204834\n",
      "Epoch 136/300, Train Loss: 0.19118241149377316, Val Loss: 8.689258480072022, R^2 Score: 0.1645653247833252\n",
      "Epoch 137/300, Train Loss: 0.23132522015812548, Val Loss: 9.063540744781495, R^2 Score: 0.12421327829360962\n",
      "Epoch 138/300, Train Loss: 0.28423296723594055, Val Loss: 9.06973991394043, R^2 Score: 0.1284080147743225\n",
      "Epoch 139/300, Train Loss: 0.43630356230634326, Val Loss: 9.181895780563355, R^2 Score: 0.12158656120300293\n",
      "Epoch 140/300, Train Loss: 0.3320498500574142, Val Loss: 8.959537792205811, R^2 Score: 0.1399109959602356\n",
      "Epoch 141/300, Train Loss: 0.615817840349801, Val Loss: 9.790004634857178, R^2 Score: 0.07587027549743652\n",
      "Epoch 142/300, Train Loss: 0.8275252894518224, Val Loss: 9.239170718193055, R^2 Score: 0.11561757326126099\n",
      "Epoch 143/300, Train Loss: 0.511308786716867, Val Loss: 8.681414079666137, R^2 Score: 0.16674524545669556\n",
      "Epoch 144/300, Train Loss: 0.25983542964813555, Val Loss: 9.128503704071045, R^2 Score: 0.12017565965652466\n",
      "Epoch 145/300, Train Loss: 0.15799787771353063, Val Loss: 8.878166198730469, R^2 Score: 0.1445242166519165\n",
      "Epoch 146/300, Train Loss: 0.1447761516542511, Val Loss: 8.76920735836029, R^2 Score: 0.15284216403961182\n",
      "Epoch 147/300, Train Loss: 0.12356931850948233, Val Loss: 8.719400787353516, R^2 Score: 0.15986120700836182\n",
      "Epoch 148/300, Train Loss: 0.1423336877388523, Val Loss: 8.740320825576783, R^2 Score: 0.15952879190444946\n",
      "Epoch 149/300, Train Loss: 0.13723197329710138, Val Loss: 8.964543342590332, R^2 Score: 0.14227288961410522\n",
      "Epoch 150/300, Train Loss: 0.14130798814461587, Val Loss: 8.77758240699768, R^2 Score: 0.1604013442993164\n",
      "Epoch 151/300, Train Loss: 0.15800384539080428, Val Loss: 9.03651671409607, R^2 Score: 0.13131558895111084\n",
      "Epoch 152/300, Train Loss: 0.1469091377121971, Val Loss: 9.132357120513916, R^2 Score: 0.12495994567871094\n",
      "Epoch 153/300, Train Loss: 0.16182507198066154, Val Loss: 9.248637533187866, R^2 Score: 0.11194038391113281\n",
      "Epoch 154/300, Train Loss: 0.13139508272263598, Val Loss: 8.759439039230347, R^2 Score: 0.154385507106781\n",
      "Epoch 155/300, Train Loss: 0.11442333483632575, Val Loss: 8.774176406860352, R^2 Score: 0.1533096432685852\n",
      "Epoch 156/300, Train Loss: 0.13504622282182915, Val Loss: 8.900545263290406, R^2 Score: 0.14700955152511597\n",
      "Epoch 157/300, Train Loss: 0.131319509185058, Val Loss: 8.801736569404602, R^2 Score: 0.15141183137893677\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MedicalResNetModel(\n\u001b[0;32m      3\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[0;32m      4\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#pretrained=False\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#model.evaluate()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\base_medical.py:146\u001b[0m, in \u001b[0;36mMedicalResNetModelBase.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m--> 146\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([value\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\monai\\data\\meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32mc:\\Users\\askel\\anaconda3\\envs\\MLA\\Lib\\site-packages\\torch\\_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a model instance\n",
    "model = MedicalResNetModel(\n",
    "    num_epochs=300,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    data_loader=data_loader,\n",
    "    dropout_rate=0.1,\n",
    "    depth=18\n",
    "    #pretrained=False\n",
    ")\n",
    "\n",
    "# model.load_model('MedicalResNetModel_18_6212_epoch_38.pth')\n",
    "model.train()\n",
    "#model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_7095_height_384_epoch_3_val_8.28_r2_8.28.pth, epoch: 3, val_loss: 8.276688201086861\n",
      "Is cuda available:  True cuda\n",
      "Number of training images: 7095\n",
      "Epoch 1/300, Train Loss: 6.096595895182979, Val Loss: 8.200571204934802, R^2 Score: 0.09948539733886719\n",
      "Model saved at c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_7095_height_384_epoch_1_val_8.2_r2_8.2.pth\n",
      "Epoch 2/300, Train Loss: 5.4524619552466245, Val Loss: 8.648635404450554, R^2 Score: 0.05119889974594116\n",
      "Epoch 3/300, Train Loss: 4.3079733043103605, Val Loss: 8.540041054998126, R^2 Score: 0.06040060520172119\n",
      "Epoch 4/300, Train Loss: 3.6136485032133154, Val Loss: 8.663720658847264, R^2 Score: 0.04945254325866699\n",
      "Epoch 5/300, Train Loss: 2.9728765251400233, Val Loss: 9.504139593669347, R^2 Score: -0.04382002353668213\n",
      "Epoch 6/300, Train Loss: 2.58983155789676, Val Loss: 9.766804439680916, R^2 Score: -0.0716623067855835\n",
      "Epoch 7/300, Train Loss: 2.1586765512689814, Val Loss: 8.91195273399353, R^2 Score: 0.021639585494995117\n",
      "Epoch 8/300, Train Loss: 1.7790897974559852, Val Loss: 8.746871871607643, R^2 Score: 0.04236447811126709\n",
      "Epoch 9/300, Train Loss: 1.5815825478450671, Val Loss: 8.836355762822288, R^2 Score: 0.029817581176757812\n",
      "Epoch 10/300, Train Loss: 1.2670076310903102, Val Loss: 8.853448361158371, R^2 Score: 0.029103994369506836\n",
      "Epoch 11/300, Train Loss: 1.0899836101510503, Val Loss: 9.78529760667256, R^2 Score: -0.07645308971405029\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_7095_height_384_epoch_15_val_8.07_r2_8.07.pth\n",
    "\n",
    "\n",
    "# evaluate with the best model\n",
    "# model.load_model('c:\\Datalogi\\Bachelor\\XAI-in-Medical-Image-Analysis\\src\\models\\medical_models\\saved_models\\MedicalResNetModel_18_7095_height_384_epoch_3_val_8.28_r2_8.28.pth')\n",
    "# model.train()\n",
    "# model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
